{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of DeepSpeed on colab CLI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9mmhJzcgHy1",
        "outputId": "c57d8507-8cb1-43d0-a7c9-dbaf5991a3e5"
      },
      "source": [
        "# need to match the system-wide installed cuda-11 for deepspeed to compile\n",
        "# so install the matching pytorch\n",
        "\n",
        "# pt-1.8 doesn't have cu110 build at the moment. \n",
        "# colab will eventually upgrade to cuda-11.1 and then we can use 1.8.0+cu111\n",
        "# \n",
        "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.7.1+cu110 in /usr/local/lib/python3.7/dist-packages (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision==0.8.2+cu110 in /usr/local/lib/python3.7/dist-packages (0.8.2+cu110)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aNVOVxab2Ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568e1670-ca54-497b-c9c4-0bb825aaab21"
      },
      "source": [
        "# either install the release\n",
        "#!pip install deepspeed\n",
        "# or the master \n",
        "!pip install git+https://github.com/microsoft/deepspeed"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/microsoft/deepspeed\n",
            "  Cloning https://github.com/microsoft/deepspeed to /tmp/pip-req-build-ocznqahs\n",
            "  Running command git clone -q https://github.com/microsoft/deepspeed /tmp/pip-req-build-ocznqahs\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied (use --upgrade to upgrade): deepspeed==0.3.11+564eb4b from git+https://github.com/microsoft/deepspeed in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (1.7.1+cu110)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (0.8.2+cu110)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (4.41.1)\n",
            "Requirement already satisfied: tensorboardX==1.8 in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (1.8)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (1.10.0.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (1.19.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from deepspeed==0.3.11+564eb4b) (5.4.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->deepspeed==0.3.11+564eb4b) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.4.0->deepspeed==0.3.11+564eb4b) (7.0.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.11+564eb4b) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==1.8->deepspeed==0.3.11+564eb4b) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.2.0->tensorboardX==1.8->deepspeed==0.3.11+564eb4b) (54.0.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.3.11+564eb4b-cp37-none-any.whl size=335679 sha256=2765352eeeb8f1e699a4d85ff8253211c041cf0e6e72f85bf5837ad49815a8c1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p36m30ku/wheels/33/7c/6d/1ac44092dd4e4b5ddd1dec9474fed46ec3fe5588be7b6ffe9e\n",
            "Successfully built deepspeed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZQAIH70Yykn",
        "outputId": "54c1ce6e-a7b9-4629-c004-620b48d8f890"
      },
      "source": [
        "%%bash\r\n",
        "git clone https://github.com/huggingface/transformers\r\n",
        "cd transformers\r\n",
        "# examples change a lot so let's pick a sha that we know this notebook will work with\r\n",
        "# comment out/remove the next line if you want the master\r\n",
        "git checkout 1aa9c13f70ae75be7fd6\r\n",
        "pip install -e .\r\n",
        "pip install -r examples/_tests_requirements.txt\r\n",
        "\r\n",
        "# if needed free up some space used by cached pip packages\r\n",
        "# rm -rf /root/.cache/pip\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (0.10.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0.dev0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0.dev0) (7.1.2)\n",
            "Installing collected packages: transformers\n",
            "  Found existing installation: transformers 4.4.0.dev0\n",
            "    Can't uninstall 'transformers'. No files were found to uninstall.\n",
            "  Running setup.py develop for transformers\n",
            "Successfully installed transformers\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 2)) (0.22.2.post1)\n",
            "Processing /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f/seqeval-1.2.2-cp37-none-any.whl\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Using cached https://files.pythonhosted.org/packages/7e/57/0c7ca4e31a126189dab99c19951910bd081dea5bbd25f24b77107750eae7/sacrebleu-1.5.1-py3-none-any.whl\n",
            "Collecting rouge-score\n",
            "  Using cached https://files.pythonhosted.org/packages/1f/56/a81022436c08b9405a5247b71635394d44fe7e1dbedc4b28c740e09c2840/rouge_score-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 7)) (4.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 8)) (3.2.2)\n",
            "Collecting git-python==1.0.3\n",
            "  Using cached https://files.pythonhosted.org/packages/8a/de/0cc6353a45cdb1e137cffac5383097b300cc578e2e1133eeb847e23a1394/git_python-1.0.3-py2.py3-none-any.whl\n",
            "Collecting faiss-cpu\n",
            "  Using cached https://files.pythonhosted.org/packages/48/0c/efd43c4feac172867409f38f07949c36602355ec7196749d10f905d09228/faiss_cpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Collecting streamlit\n",
            "  Using cached https://files.pythonhosted.org/packages/5f/3c/f0a97b684a49bd043bef9f8b8f4092b8a25bee9ad9a3f5e121a7161ded8f/streamlit-0.78.0-py2.py3-none-any.whl\n",
            "Collecting elasticsearch\n",
            "  Using cached https://files.pythonhosted.org/packages/72/68/76c5d46cc6a48fddb759f585bc8728caa11bfc9b812ce6705fc5f99beab2/elasticsearch-7.11.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 13)) (3.2.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 14)) (1.1.5)\n",
            "Collecting datasets>=1.1.3\n",
            "  Using cached https://files.pythonhosted.org/packages/3e/73/742d17d8a9a1c639132affccc9250f0743e484cbf263ede6ddcbe34ef212/datasets-1.4.1-py3-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/af/19/30/1ea0cad502dcb4e66ed5a690279628c827aea38bbbab75d5ed/fire-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 17)) (3.6.4)\n",
            "Collecting conllu\n",
            "  Using cached https://files.pythonhosted.org/packages/ae/be/be6959c3ff2dbfdd87de4be0ccdff577835b5d08b1d25bf7fd4aaf0d7add/conllu-4.4-py2.py3-none-any.whl\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Using cached https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r examples/_tests_requirements.txt (line 20)) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.27.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (54.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.3.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r examples/_tests_requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r examples/_tests_requirements.txt (line 2)) (1.4.1)\n",
            "Collecting portalocker==2.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (5.1.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.28.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (20.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (0.3.3)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r examples/_tests_requirements.txt (line 8)) (1.3.1)\n",
            "Collecting gitpython\n",
            "  Using cached https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.1)\n",
            "Collecting base58\n",
            "  Using cached https://files.pythonhosted.org/packages/b8/a1/d9f565e9910c09fd325dc638765e8843a19fa696275c16cc08cf3b0a3c25/base58-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (7.1.2)\n",
            "Collecting pydeck>=0.1.dev5\n",
            "  Using cached https://files.pythonhosted.org/packages/1c/3f/8f04ae0c22d82ec7bec7fcc03270a142f637e362bbd285f7daeeda24fbef/pydeck-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (3.0.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (1.5.1)\n",
            "Collecting validators\n",
            "  Using cached https://files.pythonhosted.org/packages/db/2f/7fed3ee94ad665ad2c1de87f858f10a7785251ff75b4fd47987888d07ef1/validators-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (4.2.1)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (5.1.1)\n",
            "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (4.1.0)\n",
            "Collecting blinker\n",
            "  Using cached https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz\n",
            "Collecting watchdog; platform_system != \"Darwin\"\n",
            "  Using cached https://files.pythonhosted.org/packages/c6/ba/a36ca5b4e75649a002f06531862467b3eb5c768caa23d6d88b921fe238d8/watchdog-2.0.2-py3-none-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (20.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (7.0.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->-r examples/_tests_requirements.txt (line 11)) (0.10.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r examples/_tests_requirements.txt (line 12)) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from elasticsearch->-r examples/_tests_requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r examples/_tests_requirements.txt (line 14)) (2018.9)\n",
            "Collecting fsspec\n",
            "  Using cached https://files.pythonhosted.org/packages/91/0d/a6bfee0ddf47b254286b9bd574e6f50978c69897647ae15b14230711806e/fsspec-0.8.7-py3-none-any.whl\n",
            "Collecting xxhash\n",
            "  Using cached https://files.pythonhosted.org/packages/e7/27/1c0b37c53a7852f1c190ba5039404d27b3ae96a55f48203a74259f8213c9/xxhash-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl\n",
            "Collecting huggingface-hub==0.0.2\n",
            "  Using cached https://files.pythonhosted.org/packages/b5/93/7cb0755c62c36cdadc70c79a95681df685b52cbaf76c724facb6ecac3272/huggingface_hub-0.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.7.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (0.70.11.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (8.7.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->-r examples/_tests_requirements.txt (line 17)) (0.7.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/_tests_requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/_tests_requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r examples/_tests_requirements.txt (line 7)) (1.53.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl\n",
            "Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n",
            "  Using cached https://files.pythonhosted.org/packages/56/95/3a670c8b2c2370bd8631c313f42e60983b3113ffec4035940592252bd6d5/ipykernel-5.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (7.6.3)\n",
            "Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.11.3)\n",
            "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.0.5)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.6.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.2->datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r examples/_tests_requirements.txt (line 15)) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->-r examples/_tests_requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/_tests_requirements.txt (line 1)) (3.1.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Using cached https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (7.21.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.3.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (3.0.16)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.18.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (22.0.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (4.7.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.2.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.9.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r examples/_tests_requirements.txt (line 11)) (0.5.1)\n",
            "Building wheels for collected packages: blinker\n",
            "  Building wheel for blinker (setup.py): started\n",
            "  Building wheel for blinker (setup.py): finished with status 'done'\n",
            "  Created wheel for blinker: filename=blinker-1.4-cp37-none-any.whl size=13448 sha256=1229ae33365339a6436b8d0289685f11f72f0067e36d137c148cd183f72cd712\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n",
            "Successfully built blinker\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, smmap, gitdb, gitpython, git-python, faiss-cpu, base58, ipykernel, pydeck, validators, blinker, watchdog, streamlit, elasticsearch, fsspec, xxhash, huggingface-hub, datasets, fire, conllu, sentencepiece\n",
            "  Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "Successfully installed base58-2.1.0 blinker-1.4 conllu-4.4 datasets-1.4.1 elasticsearch-7.11.0 faiss-cpu-1.7.0 fire-0.4.0 fsspec-0.8.7 git-python-1.0.3 gitdb-4.0.5 gitpython-3.1.14 huggingface-hub-0.0.2 ipykernel-5.5.0 portalocker-2.0.0 pydeck-0.6.1 rouge-score-0.0.4 sacrebleu-1.5.1 sentencepiece-0.1.95 seqeval-1.2.2 smmap-3.0.5 streamlit-0.78.0 validators-0.18.2 watchdog-2.0.2 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "HEAD is now at 1aa9c13f7 Fix GPU tests with speech\n",
            "ERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.16 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.5.0 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.21.0 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYG2EDAQdFxt"
      },
      "source": [
        "%%bash\n",
        "\n",
        "cd transformers\n",
        "\n",
        "cat <<'EOT' > ds_config.json\n",
        "{\n",
        "    \"fp16\": {\n",
        "        \"enabled\": true,\n",
        "        \"loss_scale\": 0,\n",
        "        \"loss_scale_window\": 1000,\n",
        "        \"initial_scale_power\": 16,        \n",
        "        \"hysteresis\": 2,\n",
        "        \"min_loss_scale\": 1\n",
        "    },\n",
        "\n",
        "    \"zero_optimization\": {\n",
        "        \"stage\": 2,\n",
        "       \"allgather_partitions\": true,\n",
        "       \"allgather_bucket_size\": 2e8,\n",
        "       \"reduce_scatter\": true,\n",
        "       \"reduce_bucket_size\": 2e8,\n",
        "        \"overlap_comm\": true,\n",
        "        \"contiguous_gradients\": true,\n",
        "        \"cpu_offload\": true\n",
        "    },\n",
        "\n",
        "    \"optimizer\": {\n",
        "        \"type\": \"AdamW\",\n",
        "        \"params\": {\n",
        "            \"lr\": 3e-5,\n",
        "            \"betas\": [ 0.9, 0.999 ],\n",
        "            \"eps\": 1e-8,\n",
        "            \"weight_decay\": 3e-7\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"scheduler\": {\n",
        "        \"type\": \"WarmupLR\",\n",
        "        \"params\": {\n",
        "            \"warmup_min_lr\": 0,\n",
        "            \"warmup_max_lr\": 3e-5,\n",
        "            \"warmup_num_steps\": 500\n",
        "        }\n",
        "    },\n",
        "    \"steps_per_print\": 2000,\n",
        "    \"wall_clock_breakdown\": false\n",
        "}\n",
        "EOT\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJKdum6zdxLE"
      },
      "source": [
        "#!ls -l transformers\n",
        "#!cat transformers/ds_config.json"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghNfx0nNZSfq",
        "outputId": "30e45fd4-e6b2-43a8-dda9-7c7164de11f1"
      },
      "source": [
        "!cd transformers; export BS=16; rm -r output_dir; PYTHONPATH=src USE_TF=0 CUDA_VISIBLE_DEVICES=0 deepspeed --num_gpus=1 examples/seq2seq/run_seq2seq.py --model_name_or_path google/mt5-small \\\r\n",
        "--output_dir output_dir --adam_eps 1e-06  --evaluation_strategy=steps  --do_train --label_smoothing 0.1 --learning_rate 3e-5 --logging_first_step --logging_steps 1000 \\\r\n",
        "--max_source_length 128 --max_target_length 128 --num_train_epochs 1 --overwrite_output_dir  --per_device_train_batch_size $BS --predict_with_generate --sortish_sampler \\\r\n",
        "--val_max_target_length 128 --warmup_steps 500 --max_train_samples 2000 --max_val_samples 500 \\\r\n",
        "--task translation_en_to_ro  --dataset_name wmt16 --dataset_config ro-en --source_prefix \"translate English to Romanian: \" --deepspeed  ds_config.json --fp16\r\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'output_dir': No such file or directory\n",
            "[2021-03-11 00:35:09,293] [WARNING] [runner.py:117:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
            "[2021-03-11 00:35:09,310] [INFO] [runner.py:358:main] cmd = /usr/bin/python3 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMF19 --master_addr=127.0.0.1 --master_port=29500 examples/seq2seq/run_seq2seq.py --model_name_or_path google/mt5-small --output_dir output_dir --adam_eps 1e-06 --evaluation_strategy=steps --do_train --label_smoothing 0.1 --learning_rate 3e-5 --logging_first_step --logging_steps 1000 --max_source_length 128 --max_target_length 128 --num_train_epochs 1 --overwrite_output_dir --per_device_train_batch_size 16 --predict_with_generate --sortish_sampler --val_max_target_length 128 --warmup_steps 500 --max_train_samples 2000 --max_val_samples 500 --task translation_en_to_ro --dataset_name wmt16 --dataset_config ro-en --source_prefix translate English to Romanian:  --deepspeed ds_config.json --fp16\n",
            "[2021-03-11 00:35:10,612] [INFO] [launch.py:73:main] 0 NCCL_VERSION 2.7.8\n",
            "[2021-03-11 00:35:10,612] [INFO] [launch.py:80:main] WORLD INFO DICT: {'localhost': [0]}\n",
            "[2021-03-11 00:35:10,613] [INFO] [launch.py:89:main] nnodes=1, num_local_procs=1, node_rank=0\n",
            "[2021-03-11 00:35:10,613] [INFO] [launch.py:101:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0]})\n",
            "[2021-03-11 00:35:10,613] [INFO] [launch.py:102:main] dist_world_size=1\n",
            "[2021-03-11 00:35:10,613] [INFO] [launch.py:105:main] Setting CUDA_VISIBLE_DEVICES=0\n",
            "[2021-03-11 00:35:15,327] [INFO] [distributed.py:47:init_distributed] Initializing torch distributed with backend: nccl\n",
            "03/11/2021 00:35:17 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
            "03/11/2021 00:35:17 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(output_dir='output_dir', overwrite_output_dir=True, do_train=True, do_eval=None, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=16, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=3e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-06, max_grad_norm=1.0, num_train_epochs=1.0, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=500, logging_dir='runs/Mar11_00-35-15_64f1962f0632', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=True, logging_steps=1000, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=0, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1000, dataloader_num_workers=0, past_index=-1, run_name='output_dir', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed='ds_config.json', label_smoothing_factor=0.1, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, sortish_sampler=True, predict_with_generate=True)\n",
            "Downloading: 2.81kB [00:00, 2.87MB/s]       \n",
            "Downloading: 3.19kB [00:00, 3.46MB/s]       \n",
            "Downloading: 41.1kB [00:00, 27.0MB/s]       \n",
            "Downloading and preparing dataset wmt16/ro-en (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/9dc00622c30446e99c4c63d12a484ea4fb653f2f37c867d6edcec839d7eae50f...\n",
            "Downloading: 100% 225M/225M [00:06<00:00, 32.4MB/s]\n",
            "Downloading: 100% 23.5M/23.5M [00:02<00:00, 10.9MB/s]\n",
            "Downloading: 100% 38.7M/38.7M [00:00<00:00, 47.9MB/s]\n",
            "Dataset wmt16 downloaded and prepared to /root/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/9dc00622c30446e99c4c63d12a484ea4fb653f2f37c867d6edcec839d7eae50f. Subsequent calls will reuse this data.\n",
            "https://huggingface.co/google/mt5-small/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp9esagqxc\n",
            "Downloading: 100% 553/553 [00:00<00:00, 597kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "creating metadata file for /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/google/mt5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/97693496c1a0cae463bd18428187f9e9924d2dfbadaa46e4d468634a0fc95a41.dadce13f8f85f4825168354a04675d4b177749f8f11b167e87676777695d4fe4\n",
            "Model config MT5Config {\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 1024,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"num_decoder_layers\": 8,\n",
            "  \"num_heads\": 6,\n",
            "  \"num_layers\": 8,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.4.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "Model name 'google/mt5-small' not found in model shortcut name list (t5-small, t5-base, t5-large, t5-3b, t5-11b). Assuming 'google/mt5-small' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "https://huggingface.co/google/mt5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpvcpy2p91\n",
            "Downloading: 100% 4.31M/4.31M [00:00<00:00, 16.7MB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "creating metadata file for /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmrig6krg\n",
            "Downloading: 100% 99.0/99.0 [00:00<00:00, 75.1kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "creating metadata file for /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpwykeg1xc\n",
            "Downloading: 100% 82.0/82.0 [00:00<00:00, 107kB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "creating metadata file for /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/37d0f67f084f8c5fc5589e0bba5ff3c6307af833bb0b7f4eb33fbfd8d4038a9d.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/685ac0ca8568ec593a48b61b0a3c272beee9bc194a3c7241d15dcadb5f875e53.f76030f3ec1b96a8199b2593390c610e76ca8028ef3d24680000619ffb646276\n",
            "loading file https://huggingface.co/google/mt5-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6a9e52d6dd21568e37b65fc180ada927968e8f7124f0acd6efcaf90cd2e0f4bb.4b81e5d952ad810ca1de2b3e362b9a26a5cc77b4b75daf20caf69fb838751c32\n",
            "https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpsgvqcs7m\n",
            "Downloading: 100% 1.20G/1.20G [00:24<00:00, 48.4MB/s]\n",
            "storing https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "creating metadata file for /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "loading weights file https://huggingface.co/google/mt5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8e7b2a80ddcb5611b27d8c89e1e8e33a947e105415051402a22b9c8d7d1caeb0.e22331f3a065b885b30ae3dd1ff11ccaf7fbc444485f6eb07ef5e0138bca8b70\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-small.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
            "100% 2/2 [00:00<00:00, 13.47ba/s]\n",
            "Downloading: 5.02kB [00:00, 3.95MB/s]       \n",
            "Using amp fp16 backend\n",
            "Keeping the `optimizer` config from ds_config.json intact, ignoring any optimizer-specific cl args\n",
            "Keeping the `scheduler` config from ds_config.json intact, ignoring any scheduler-specific cl args\n",
            "Keeping the `fp16` config from ds_config.json intact, ignoring any fp16-specific cl args\n",
            "[2021-03-11 00:36:34,533] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed info: version=0.3.11+564eb4b, git-hash=564eb4b, git-branch=master\n",
            "[2021-03-11 00:36:34,972] [INFO] [engine.py:77:_initialize_parameter_parallel_groups] data_parallel_size: 1, parameter_parallel_size: 1\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/cpu_adam...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Detected CUDA files, patching ldflags\n",
            "Emitting ninja build file /root/.cache/torch_extensions/cpu_adam/build.ninja...\n",
            "Building extension module cpu_adam...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_60,code=sm_60 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_60,code=sm_60 -gencode=arch=compute_60,code=compute_60 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
            "[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -L/usr/local/cuda/lib64 -lcudart -lcublas -g -Wno-reorder -march=native -fopenmp -D__AVX256__ -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
            "[3/3] c++ cpu_adam.o custom_cuda_kernel.cuda.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o cpu_adam.so\n",
            "Loading extension module cpu_adam...\n",
            "Time to load cpu_adam op: 27.971820831298828 seconds\n",
            "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
            "Config: alpha=0.000030, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1\n",
            "[2021-03-11 00:37:08,230] [INFO] [engine.py:596:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
            "[2021-03-11 00:37:08,230] [INFO] [engine.py:600:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
            "Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
            "[2021-03-11 00:37:08,231] [INFO] [logging.py:60:log_dist] [Rank 0] Creating fp16 ZeRO stage 2 optimizer\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "Creating extension directory /root/.cache/torch_extensions/utils...\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Emitting ninja build file /root/.cache/torch_extensions/utils/build.ninja...\n",
            "Building extension module utils...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.7/dist-packages/torch/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.7/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.7/dist-packages/torch/include/THC -isystem /usr/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /usr/local/lib/python3.7/dist-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
            "[2/2] c++ flatten_unflatten.o -shared -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 14.857433557510376 seconds\n",
            "[2021-03-11 00:37:23,089] [INFO] [stage2.py:130:__init__] Reduce bucket size 200000000.0\n",
            "[2021-03-11 00:37:23,089] [INFO] [stage2.py:131:__init__] Allgather bucket size 200000000.0\n",
            "[2021-03-11 00:37:23,089] [INFO] [stage2.py:132:__init__] CPU Offload: True\n",
            "tcmalloc: large alloc 1200709632 bytes == 0x55b4be984000 @  0x7f21deda4b6b 0x7f21dedc4379 0x7f20f7c3474e 0x7f20f7c367b6 0x7f21837bae43 0x7f21831a57ff 0x7f21834bcbdc 0x7f218346824b 0x7f2183487065 0x7f2183462a7b 0x7f218346824b 0x7f2183487065 0x7f21835511ee 0x7f2184a63d9e 0x7f218346824b 0x7f2183487065 0x7f2183462a7b 0x7f218346824b 0x7f2183487065 0x7f21835511ee 0x7f2183191730 0x7f21836be71a 0x7f2182d10081 0x7f21837aad66 0x7f218378e900 0x7f21930f866d 0x7f2193203313 0x7f219320f200 0x55b3ba4c6050 0x55b3ba5b799d 0x55b3ba539fe9\n",
            "[2021-03-11 00:37:26,441] [INFO] [stage2.py:399:__init__] optimizer state initialized\n",
            "[2021-03-11 00:37:26,442] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
            "[2021-03-11 00:37:26,442] [INFO] [engine.py:439:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR\n",
            "[2021-03-11 00:37:26,442] [INFO] [logging.py:60:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f20a90e66d0>\n",
            "[2021-03-11 00:37:26,442] [INFO] [logging.py:60:log_dist] [Rank 0] step=0, skipped=0, lr=[3e-05], mom=[[0.9, 0.999]]\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:733:print] DeepSpeedEngine configuration:\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:737:print]   activation_checkpointing_config  <deepspeed.runtime.activation_checkpointing.config.DeepSpeedActivationCheckpointingConfig object at 0x7f20e27ecd90>\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:737:print]   allreduce_always_fp32 ........ False\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:737:print]   amp_enabled .................. False\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:737:print]   amp_params ................... False\n",
            "[2021-03-11 00:37:26,442] [INFO] [config.py:737:print]   checkpoint_tag_validation_enabled  True\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   checkpoint_tag_validation_fail  False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   disable_allgather ............ False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   dump_state ................... False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 1000, 'delayed_shift': 2, 'min_scale': 1}\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   elasticity_enabled ........... False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   flops_profiler_config ........ <deepspeed.profiling.config.DeepSpeedFlopsProfilerConfig object at 0x7f20e27ecf10>\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   fp16_enabled ................. True\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   global_rank .................. 0\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   gradient_accumulation_steps .. 1\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   gradient_clipping ............ 1.0\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   gradient_predivide_factor .... 1.0\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   initial_dynamic_scale ........ 65536\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   loss_scale ................... 0\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   memory_breakdown ............. False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   optimizer_legacy_fusion ...... False\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   optimizer_name ............... adamw\n",
            "[2021-03-11 00:37:26,443] [INFO] [config.py:737:print]   optimizer_params ............. {'lr': 3e-05, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 3e-07}\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   pld_enabled .................. False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   pld_params ................... False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   prescale_gradients ........... False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   scheduler_name ............... WarmupLR\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 3e-05, 'warmup_num_steps': 500}\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   sparse_attention ............. None\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   sparse_gradients_enabled ..... False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   steps_per_print .............. 2000\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   tensorboard_enabled .......... False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   tensorboard_job_name ......... DeepSpeedJobName\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   tensorboard_output_path ...... \n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   train_batch_size ............. 16\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   train_micro_batch_size_per_gpu  16\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   wall_clock_breakdown ......... False\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   world_size ................... 1\n",
            "[2021-03-11 00:37:26,444] [INFO] [config.py:737:print]   zero_allow_untested_optimizer  False\n",
            "[2021-03-11 00:37:26,445] [INFO] [config.py:737:print]   zero_config .................. {\n",
            "    \"allgather_bucket_size\": 200000000.0,\n",
            "    \"allgather_partitions\": true,\n",
            "    \"contiguous_gradients\": true,\n",
            "    \"cpu_offload\": true,\n",
            "    \"cpu_offload_params\": false,\n",
            "    \"cpu_offload_use_pin_memory\": false,\n",
            "    \"elastic_checkpoint\": true,\n",
            "    \"load_from_fp32_weights\": true,\n",
            "    \"max_live_parameters\": 1000000000,\n",
            "    \"max_reuse_distance\": 1000000000,\n",
            "    \"overlap_comm\": true,\n",
            "    \"param_persistence_threshold\": 100000,\n",
            "    \"prefetch_bucket_size\": 50000000,\n",
            "    \"reduce_bucket_size\": 200000000.0,\n",
            "    \"reduce_scatter\": true,\n",
            "    \"stage\": 2,\n",
            "    \"sub_group_size\": 1000000000000\n",
            "}\n",
            "[2021-03-11 00:37:26,445] [INFO] [config.py:737:print]   zero_enabled ................. True\n",
            "[2021-03-11 00:37:26,445] [INFO] [config.py:737:print]   zero_optimization_stage ...... 2\n",
            "[2021-03-11 00:37:26,445] [INFO] [config.py:743:print]   json = {\n",
            "    \"fp16\":{\n",
            "        \"enabled\":true,\n",
            "        \"hysteresis\":2,\n",
            "        \"initial_scale_power\":16,\n",
            "        \"loss_scale\":0,\n",
            "        \"loss_scale_window\":1000,\n",
            "        \"min_loss_scale\":1\n",
            "    },\n",
            "    \"gradient_accumulation_steps\":1,\n",
            "    \"gradient_clipping\":1.0,\n",
            "    \"optimizer\":{\n",
            "        \"params\":{\n",
            "            \"betas\":[\n",
            "                0.9,\n",
            "                0.999\n",
            "            ],\n",
            "            \"eps\":1e-08,\n",
            "            \"lr\":3e-05,\n",
            "            \"weight_decay\":3e-07\n",
            "        },\n",
            "        \"type\":\"AdamW\"\n",
            "    },\n",
            "    \"scheduler\":{\n",
            "        \"params\":{\n",
            "            \"warmup_max_lr\":3e-05,\n",
            "            \"warmup_min_lr\":0,\n",
            "            \"warmup_num_steps\":500\n",
            "        },\n",
            "        \"type\":\"WarmupLR\"\n",
            "    },\n",
            "    \"steps_per_print\":2000,\n",
            "    \"train_micro_batch_size_per_gpu\":16,\n",
            "    \"wall_clock_breakdown\":false,\n",
            "    \"zero_optimization\":{\n",
            "        \"allgather_bucket_size\":200000000.0,\n",
            "        \"allgather_partitions\":true,\n",
            "        \"contiguous_gradients\":true,\n",
            "        \"cpu_offload\":true,\n",
            "        \"overlap_comm\":true,\n",
            "        \"reduce_bucket_size\":200000000.0,\n",
            "        \"reduce_scatter\":true,\n",
            "        \"stage\":2\n",
            "    }\n",
            "}\n",
            "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
            "No modifications detected for re-loaded extension module utils, skipping build step...\n",
            "Loading extension module utils...\n",
            "Time to load utils op: 0.0006816387176513672 seconds\n",
            "***** Running training *****\n",
            "  Num examples = 2000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 125\n",
            "2021-03-11 00:37:26.664762: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "  0% 0/125 [00:00<?, ?it/s][2021-03-11 00:37:35,132] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 65536\n",
            "  1% 1/125 [00:05<11:07,  5.39s/it]tried to get lr value before scheduler/optimizer started stepping, returning lr=0\n",
            "{'loss': nan, 'learning_rate': 0, 'epoch': 0.01}\n",
            "  1% 1/125 [00:05<11:07,  5.39s/it][2021-03-11 00:37:35,541] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768.0\n",
            "  2% 2/125 [00:05<07:58,  3.89s/it][2021-03-11 00:37:35,942] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
            "  2% 3/125 [00:06<05:47,  2.85s/it][2021-03-11 00:37:36,435] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
            "  3% 4/125 [00:06<04:18,  2.14s/it][2021-03-11 00:37:36,863] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
            "  4% 5/125 [00:07<03:15,  1.63s/it][2021-03-11 00:37:37,274] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n",
            "  5% 6/125 [00:07<02:30,  1.26s/it][2021-03-11 00:37:37,662] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0\n",
            "  6% 7/125 [00:07<01:57,  1.00it/s][2021-03-11 00:37:38,061] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1024.0, reducing to 512.0\n",
            "  6% 8/125 [00:08<01:35,  1.22it/s][2021-03-11 00:37:38,455] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 512.0, reducing to 256.0\n",
            "  7% 9/125 [00:08<01:20,  1.45it/s][2021-03-11 00:37:38,861] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 256.0, reducing to 128.0\n",
            "  8% 10/125 [00:09<01:09,  1.65it/s][2021-03-11 00:37:39,270] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 128.0, reducing to 64.0\n",
            "  9% 11/125 [00:09<01:02,  1.83it/s][2021-03-11 00:37:40,511] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.32 | optimizer_step: 655.52 | optimizer_allgather: 5.02\n",
            " 10% 12/125 [00:10<01:25,  1.32it/s][2021-03-11 00:37:40,911] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 64.0, reducing to 32.0\n",
            " 10% 13/125 [00:11<01:12,  1.54it/s][2021-03-11 00:37:41,277] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32.0, reducing to 16.0\n",
            " 11% 14/125 [00:11<01:02,  1.77it/s][2021-03-11 00:37:42,417] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.32 | optimizer_step: 639.41 | optimizer_allgather: 4.93\n",
            " 12% 15/125 [00:12<01:21,  1.36it/s][2021-03-11 00:37:43,522] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.55 | optimizer_step: 644.31 | optimizer_allgather: 4.94\n",
            " 13% 16/125 [00:13<01:32,  1.18it/s][2021-03-11 00:37:44,667] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.88 | optimizer_step: 636.39 | optimizer_allgather: 4.90\n",
            " 14% 17/125 [00:14<01:41,  1.07it/s][2021-03-11 00:37:45,820] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 97.05 | optimizer_step: 639.21 | optimizer_allgather: 4.89\n",
            " 14% 18/125 [00:16<01:47,  1.00s/it][2021-03-11 00:37:46,925] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 96.38 | optimizer_step: 638.64 | optimizer_allgather: 4.90\n",
            " 15% 19/125 [00:17<01:49,  1.03s/it][2021-03-11 00:37:47,352] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16.0, reducing to 8.0\n",
            " 16% 20/125 [00:17<01:29,  1.18it/s][2021-03-11 00:37:48,479] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.20 | optimizer_step: 637.22 | optimizer_allgather: 4.90\n",
            " 17% 21/125 [00:18<01:37,  1.07it/s][2021-03-11 00:37:49,632] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.79 | optimizer_step: 640.61 | optimizer_allgather: 4.92\n",
            " 18% 22/125 [00:19<01:42,  1.00it/s][2021-03-11 00:37:50,778] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.90 | optimizer_step: 636.85 | optimizer_allgather: 4.92\n",
            " 18% 23/125 [00:21<01:46,  1.04s/it][2021-03-11 00:37:51,892] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 92.57 | optimizer_step: 644.31 | optimizer_allgather: 4.96\n",
            " 19% 24/125 [00:22<01:47,  1.06s/it][2021-03-11 00:37:53,050] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.77 | optimizer_step: 639.22 | optimizer_allgather: 4.87\n",
            " 20% 25/125 [00:23<01:49,  1.09s/it][2021-03-11 00:37:54,178] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 96.51 | optimizer_step: 638.22 | optimizer_allgather: 4.94\n",
            " 21% 26/125 [00:24<01:49,  1.10s/it][2021-03-11 00:37:55,317] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.70 | optimizer_step: 638.68 | optimizer_allgather: 4.89\n",
            " 22% 27/125 [00:25<01:49,  1.11s/it][2021-03-11 00:37:56,484] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.26 | optimizer_step: 631.36 | optimizer_allgather: 4.91\n",
            " 22% 28/125 [00:26<01:49,  1.13s/it][2021-03-11 00:37:57,644] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.60 | optimizer_step: 639.28 | optimizer_allgather: 4.89\n",
            " 23% 29/125 [00:27<01:49,  1.14s/it][2021-03-11 00:37:58,793] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.75 | optimizer_step: 630.14 | optimizer_allgather: 4.93\n",
            " 24% 30/125 [00:29<01:48,  1.14s/it][2021-03-11 00:37:59,898] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.66 | optimizer_step: 626.08 | optimizer_allgather: 4.90\n",
            " 25% 31/125 [00:30<01:46,  1.13s/it][2021-03-11 00:38:01,001] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.24 | optimizer_step: 629.98 | optimizer_allgather: 4.97\n",
            " 26% 32/125 [00:31<01:44,  1.12s/it][2021-03-11 00:38:02,109] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.11 | optimizer_step: 623.38 | optimizer_allgather: 4.91\n",
            " 26% 33/125 [00:32<01:42,  1.12s/it][2021-03-11 00:38:03,261] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.28 | optimizer_step: 637.60 | optimizer_allgather: 4.91\n",
            " 27% 34/125 [00:33<01:42,  1.13s/it][2021-03-11 00:38:04,416] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.15 | optimizer_step: 626.82 | optimizer_allgather: 4.89\n",
            " 28% 35/125 [00:34<01:42,  1.14s/it][2021-03-11 00:38:05,549] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.29 | optimizer_step: 638.97 | optimizer_allgather: 4.95\n",
            " 29% 36/125 [00:35<01:41,  1.14s/it][2021-03-11 00:38:06,691] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.42 | optimizer_step: 639.95 | optimizer_allgather: 4.88\n",
            " 30% 37/125 [00:36<01:40,  1.14s/it][2021-03-11 00:38:07,872] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.68 | optimizer_step: 650.87 | optimizer_allgather: 4.91\n",
            " 30% 38/125 [00:38<01:40,  1.15s/it][2021-03-11 00:38:08,976] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 96.65 | optimizer_step: 640.34 | optimizer_allgather: 4.89\n",
            " 31% 39/125 [00:39<01:37,  1.14s/it][2021-03-11 00:38:10,167] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.37 | optimizer_step: 645.90 | optimizer_allgather: 4.91\n",
            " 32% 40/125 [00:40<01:37,  1.15s/it][2021-03-11 00:38:11,349] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.53 | optimizer_step: 641.84 | optimizer_allgather: 4.96\n",
            " 33% 41/125 [00:41<01:37,  1.16s/it][2021-03-11 00:38:12,490] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 106.32 | optimizer_step: 619.66 | optimizer_allgather: 4.93\n",
            " 34% 42/125 [00:42<01:35,  1.16s/it][2021-03-11 00:38:13,641] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.70 | optimizer_step: 640.03 | optimizer_allgather: 4.94\n",
            " 34% 43/125 [00:43<01:34,  1.15s/it][2021-03-11 00:38:14,782] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.92 | optimizer_step: 599.43 | optimizer_allgather: 4.90\n",
            " 35% 44/125 [00:45<01:33,  1.15s/it][2021-03-11 00:38:15,145] [INFO] [stage2.py:1361:step] [deepscale] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8.0, reducing to 4.0\n",
            " 36% 45/125 [00:45<01:13,  1.09it/s][2021-03-11 00:38:16,292] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.36 | optimizer_step: 645.64 | optimizer_allgather: 4.92\n",
            " 37% 46/125 [00:46<01:17,  1.02it/s][2021-03-11 00:38:17,457] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.90 | optimizer_step: 643.57 | optimizer_allgather: 4.89\n",
            " 38% 47/125 [00:47<01:20,  1.04s/it][2021-03-11 00:38:18,583] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.92 | optimizer_step: 632.99 | optimizer_allgather: 4.89\n",
            " 38% 48/125 [00:48<01:21,  1.06s/it][2021-03-11 00:38:19,694] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.71 | optimizer_step: 639.90 | optimizer_allgather: 4.90\n",
            " 39% 49/125 [00:49<01:21,  1.08s/it][2021-03-11 00:38:20,821] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.39 | optimizer_step: 620.75 | optimizer_allgather: 4.90\n",
            " 40% 50/125 [00:51<01:21,  1.09s/it][2021-03-11 00:38:21,961] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.97 | optimizer_step: 628.03 | optimizer_allgather: 4.88\n",
            " 41% 51/125 [00:52<01:21,  1.11s/it][2021-03-11 00:38:23,124] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.92 | optimizer_step: 633.17 | optimizer_allgather: 4.93\n",
            " 42% 52/125 [00:53<01:22,  1.12s/it][2021-03-11 00:38:24,258] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 107.75 | optimizer_step: 629.13 | optimizer_allgather: 4.89\n",
            " 42% 53/125 [00:54<01:21,  1.13s/it][2021-03-11 00:38:25,387] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.05 | optimizer_step: 635.22 | optimizer_allgather: 4.91\n",
            " 43% 54/125 [00:55<01:20,  1.13s/it][2021-03-11 00:38:26,533] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.19 | optimizer_step: 634.90 | optimizer_allgather: 4.89\n",
            " 44% 55/125 [00:56<01:19,  1.13s/it][2021-03-11 00:38:27,696] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.36 | optimizer_step: 636.78 | optimizer_allgather: 4.87\n",
            " 45% 56/125 [00:57<01:18,  1.14s/it][2021-03-11 00:38:28,843] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.61 | optimizer_step: 648.50 | optimizer_allgather: 4.90\n",
            " 46% 57/125 [00:59<01:17,  1.14s/it][2021-03-11 00:38:30,004] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.11 | optimizer_step: 645.08 | optimizer_allgather: 4.91\n",
            " 46% 58/125 [01:00<01:16,  1.15s/it][2021-03-11 00:38:31,160] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.91 | optimizer_step: 644.57 | optimizer_allgather: 4.88\n",
            " 47% 59/125 [01:01<01:15,  1.15s/it][2021-03-11 00:38:32,320] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.33 | optimizer_step: 612.85 | optimizer_allgather: 4.93\n",
            " 48% 60/125 [01:02<01:15,  1.15s/it][2021-03-11 00:38:33,466] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.72 | optimizer_step: 629.89 | optimizer_allgather: 4.91\n",
            " 49% 61/125 [01:03<01:13,  1.15s/it][2021-03-11 00:38:34,552] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.83 | optimizer_step: 608.51 | optimizer_allgather: 4.91\n",
            " 50% 62/125 [01:04<01:11,  1.13s/it][2021-03-11 00:38:35,658] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.24 | optimizer_step: 633.04 | optimizer_allgather: 4.98\n",
            " 50% 63/125 [01:05<01:09,  1.12s/it][2021-03-11 00:38:36,765] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.23 | optimizer_step: 602.77 | optimizer_allgather: 4.92\n",
            " 51% 64/125 [01:07<01:08,  1.12s/it][2021-03-11 00:38:37,874] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.88 | optimizer_step: 631.70 | optimizer_allgather: 4.96\n",
            " 52% 65/125 [01:08<01:06,  1.12s/it][2021-03-11 00:38:38,951] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.38 | optimizer_step: 614.14 | optimizer_allgather: 4.93\n",
            " 53% 66/125 [01:09<01:05,  1.10s/it][2021-03-11 00:38:40,077] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.64 | optimizer_step: 624.81 | optimizer_allgather: 4.91\n",
            " 54% 67/125 [01:10<01:04,  1.11s/it][2021-03-11 00:38:41,193] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.90 | optimizer_step: 608.79 | optimizer_allgather: 4.91\n",
            " 54% 68/125 [01:11<01:03,  1.11s/it][2021-03-11 00:38:42,289] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.16 | optimizer_step: 624.88 | optimizer_allgather: 4.90\n",
            " 55% 69/125 [01:12<01:02,  1.11s/it][2021-03-11 00:38:43,390] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.29 | optimizer_step: 610.57 | optimizer_allgather: 4.97\n",
            " 56% 70/125 [01:13<01:00,  1.11s/it][2021-03-11 00:38:44,502] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.32 | optimizer_step: 639.66 | optimizer_allgather: 4.91\n",
            " 57% 71/125 [01:14<00:59,  1.11s/it][2021-03-11 00:38:45,583] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 105.82 | optimizer_step: 604.99 | optimizer_allgather: 4.95\n",
            " 58% 72/125 [01:15<00:58,  1.10s/it][2021-03-11 00:38:46,737] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.48 | optimizer_step: 634.98 | optimizer_allgather: 4.90\n",
            " 58% 73/125 [01:16<00:58,  1.12s/it][2021-03-11 00:38:47,871] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 97.01 | optimizer_step: 604.86 | optimizer_allgather: 4.91\n",
            " 59% 74/125 [01:18<00:57,  1.12s/it][2021-03-11 00:38:48,990] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.32 | optimizer_step: 626.38 | optimizer_allgather: 4.88\n",
            " 60% 75/125 [01:19<00:56,  1.12s/it][2021-03-11 00:38:50,064] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.41 | optimizer_step: 601.14 | optimizer_allgather: 4.90\n",
            " 61% 76/125 [01:20<00:54,  1.11s/it][2021-03-11 00:38:51,201] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.91 | optimizer_step: 633.39 | optimizer_allgather: 4.89\n",
            " 62% 77/125 [01:21<00:53,  1.12s/it][2021-03-11 00:38:52,305] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.23 | optimizer_step: 620.63 | optimizer_allgather: 4.90\n",
            " 62% 78/125 [01:22<00:52,  1.11s/it][2021-03-11 00:38:53,410] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.46 | optimizer_step: 631.86 | optimizer_allgather: 4.89\n",
            " 63% 79/125 [01:23<00:51,  1.11s/it][2021-03-11 00:38:54,547] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.18 | optimizer_step: 632.74 | optimizer_allgather: 4.88\n",
            " 64% 80/125 [01:24<00:50,  1.12s/it][2021-03-11 00:38:55,716] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.11 | optimizer_step: 633.61 | optimizer_allgather: 4.96\n",
            " 65% 81/125 [01:25<00:49,  1.13s/it][2021-03-11 00:38:56,843] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 93.98 | optimizer_step: 639.55 | optimizer_allgather: 4.90\n",
            " 66% 82/125 [01:27<00:48,  1.13s/it][2021-03-11 00:38:57,945] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.63 | optimizer_step: 635.76 | optimizer_allgather: 4.91\n",
            " 66% 83/125 [01:28<00:47,  1.12s/it][2021-03-11 00:38:59,040] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.31 | optimizer_step: 631.27 | optimizer_allgather: 4.91\n",
            " 67% 84/125 [01:29<00:45,  1.11s/it][2021-03-11 00:39:00,147] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 97.62 | optimizer_step: 638.56 | optimizer_allgather: 5.00\n",
            " 68% 85/125 [01:30<00:44,  1.11s/it][2021-03-11 00:39:01,302] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.42 | optimizer_step: 644.53 | optimizer_allgather: 4.90\n",
            " 69% 86/125 [01:31<00:43,  1.12s/it][2021-03-11 00:39:02,433] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.40 | optimizer_step: 638.66 | optimizer_allgather: 4.90\n",
            " 70% 87/125 [01:32<00:42,  1.13s/it][2021-03-11 00:39:03,562] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.18 | optimizer_step: 636.52 | optimizer_allgather: 4.90\n",
            " 70% 88/125 [01:33<00:41,  1.13s/it][2021-03-11 00:39:04,677] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.66 | optimizer_step: 647.57 | optimizer_allgather: 4.95\n",
            " 71% 89/125 [01:34<00:40,  1.12s/it][2021-03-11 00:39:05,787] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.83 | optimizer_step: 636.93 | optimizer_allgather: 4.90\n",
            " 72% 90/125 [01:36<00:39,  1.12s/it][2021-03-11 00:39:06,912] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.15 | optimizer_step: 634.96 | optimizer_allgather: 4.89\n",
            " 73% 91/125 [01:37<00:38,  1.12s/it][2021-03-11 00:39:08,020] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.03 | optimizer_step: 641.43 | optimizer_allgather: 4.99\n",
            " 74% 92/125 [01:38<00:36,  1.12s/it][2021-03-11 00:39:09,181] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.22 | optimizer_step: 643.95 | optimizer_allgather: 4.87\n",
            " 74% 93/125 [01:39<00:36,  1.13s/it][2021-03-11 00:39:10,348] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.92 | optimizer_step: 643.71 | optimizer_allgather: 4.94\n",
            " 75% 94/125 [01:40<00:35,  1.14s/it][2021-03-11 00:39:11,495] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.57 | optimizer_step: 632.43 | optimizer_allgather: 4.89\n",
            " 76% 95/125 [01:41<00:34,  1.14s/it][2021-03-11 00:39:12,634] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 99.87 | optimizer_step: 642.40 | optimizer_allgather: 4.87\n",
            " 77% 96/125 [01:42<00:33,  1.14s/it][2021-03-11 00:39:13,796] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 104.14 | optimizer_step: 633.76 | optimizer_allgather: 4.90\n",
            " 78% 97/125 [01:44<00:32,  1.15s/it][2021-03-11 00:39:14,957] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 106.17 | optimizer_step: 619.66 | optimizer_allgather: 4.90\n",
            " 78% 98/125 [01:45<00:31,  1.15s/it][2021-03-11 00:39:16,067] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 105.71 | optimizer_step: 642.77 | optimizer_allgather: 4.92\n",
            " 79% 99/125 [01:46<00:29,  1.14s/it][2021-03-11 00:39:17,154] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.79 | optimizer_step: 615.58 | optimizer_allgather: 4.89\n",
            " 80% 100/125 [01:47<00:28,  1.12s/it][2021-03-11 00:39:18,290] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.65 | optimizer_step: 639.18 | optimizer_allgather: 4.91\n",
            " 81% 101/125 [01:48<00:27,  1.13s/it][2021-03-11 00:39:19,497] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.86 | optimizer_step: 639.23 | optimizer_allgather: 4.92\n",
            " 82% 102/125 [01:49<00:26,  1.15s/it][2021-03-11 00:39:20,684] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.27 | optimizer_step: 647.24 | optimizer_allgather: 4.92\n",
            " 82% 103/125 [01:50<00:25,  1.16s/it][2021-03-11 00:39:21,782] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 97.50 | optimizer_step: 635.03 | optimizer_allgather: 4.90\n",
            " 83% 104/125 [01:52<00:23,  1.14s/it][2021-03-11 00:39:22,958] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.46 | optimizer_step: 640.20 | optimizer_allgather: 4.88\n",
            " 84% 105/125 [01:53<00:23,  1.15s/it][2021-03-11 00:39:24,094] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.79 | optimizer_step: 646.26 | optimizer_allgather: 4.91\n",
            " 85% 106/125 [01:54<00:21,  1.15s/it][2021-03-11 00:39:25,217] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 104.66 | optimizer_step: 624.81 | optimizer_allgather: 4.96\n",
            " 86% 107/125 [01:55<00:20,  1.14s/it][2021-03-11 00:39:26,359] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 103.69 | optimizer_step: 638.57 | optimizer_allgather: 4.92\n",
            " 86% 108/125 [01:56<00:19,  1.14s/it][2021-03-11 00:39:27,488] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.45 | optimizer_step: 601.27 | optimizer_allgather: 4.91\n",
            " 87% 109/125 [01:57<00:18,  1.14s/it][2021-03-11 00:39:28,644] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.06 | optimizer_step: 624.86 | optimizer_allgather: 4.92\n",
            " 88% 110/125 [01:58<00:17,  1.14s/it][2021-03-11 00:39:29,751] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.01 | optimizer_step: 605.81 | optimizer_allgather: 4.92\n",
            " 89% 111/125 [02:00<00:15,  1.13s/it][2021-03-11 00:39:30,956] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 102.04 | optimizer_step: 640.59 | optimizer_allgather: 4.89\n",
            " 90% 112/125 [02:01<00:15,  1.15s/it][2021-03-11 00:39:32,116] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.46 | optimizer_step: 642.69 | optimizer_allgather: 4.92\n",
            " 90% 113/125 [02:02<00:13,  1.16s/it][2021-03-11 00:39:33,234] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 96.70 | optimizer_step: 630.63 | optimizer_allgather: 4.93\n",
            " 91% 114/125 [02:03<00:12,  1.14s/it][2021-03-11 00:39:34,367] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 97.12 | optimizer_step: 641.63 | optimizer_allgather: 4.93\n",
            " 92% 115/125 [02:04<00:11,  1.14s/it][2021-03-11 00:39:35,491] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 95.17 | optimizer_step: 635.27 | optimizer_allgather: 4.89\n",
            " 93% 116/125 [02:05<00:10,  1.14s/it][2021-03-11 00:39:36,612] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.74 | optimizer_step: 644.72 | optimizer_allgather: 4.95\n",
            " 94% 117/125 [02:06<00:09,  1.13s/it][2021-03-11 00:39:37,746] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 94.41 | optimizer_step: 636.05 | optimizer_allgather: 4.96\n",
            " 94% 118/125 [02:08<00:07,  1.13s/it][2021-03-11 00:39:38,864] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.45 | optimizer_step: 647.27 | optimizer_allgather: 4.94\n",
            " 95% 119/125 [02:09<00:06,  1.13s/it][2021-03-11 00:39:39,966] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 93.74 | optimizer_step: 641.76 | optimizer_allgather: 4.89\n",
            " 96% 120/125 [02:10<00:05,  1.12s/it][2021-03-11 00:39:41,101] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.82 | optimizer_step: 641.71 | optimizer_allgather: 4.93\n",
            " 97% 121/125 [02:11<00:04,  1.12s/it][2021-03-11 00:39:42,261] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 98.90 | optimizer_step: 640.74 | optimizer_allgather: 4.91\n",
            " 98% 122/125 [02:12<00:03,  1.14s/it][2021-03-11 00:39:43,394] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 100.20 | optimizer_step: 639.56 | optimizer_allgather: 4.91\n",
            " 98% 123/125 [02:13<00:02,  1.13s/it][2021-03-11 00:39:44,537] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 105.06 | optimizer_step: 636.00 | optimizer_allgather: 4.90\n",
            " 99% 124/125 [02:14<00:01,  1.14s/it][2021-03-11 00:39:45,720] [INFO] [logging.py:60:log_dist] [Rank 0] rank=0 time (ms) | optimizer_gradients: 101.29 | optimizer_step: 639.88 | optimizer_allgather: 4.88\n",
            "100% 125/125 [02:15<00:00,  1.15s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 139.2795, 'train_samples_per_second': 0.897, 'epoch': 1.0}\n",
            "100% 125/125 [02:15<00:00,  1.09s/it]\n",
            "Saving model checkpoint to output_dir\n",
            "Configuration saved in output_dir/config.json\n",
            "Model weights saved in output_dir/pytorch_model.bin\n",
            "tokenizer config file saved in output_dir/tokenizer_config.json\n",
            "Special tokens file saved in output_dir/special_tokens_map.json\n",
            "Copy vocab file to output_dir/spiece.model\n",
            "***** train metrics *****\n",
            "  epoch                      =      1.0\n",
            "  init_mem_cpu_alloc_delta   =      2MB\n",
            "  init_mem_cpu_peaked_delta  =      0MB\n",
            "  init_mem_gpu_alloc_delta   =      0MB\n",
            "  init_mem_gpu_peaked_delta  =      0MB\n",
            "  train_mem_cpu_alloc_delta  =     79MB\n",
            "  train_mem_cpu_peaked_delta =      0MB\n",
            "  train_mem_gpu_alloc_delta  =    816MB\n",
            "  train_mem_gpu_peaked_delta =   6553MB\n",
            "  train_runtime              = 139.2795\n",
            "  train_samples              =     2000\n",
            "  train_samples_per_second   =    0.897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSlYvQWLwblN"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}