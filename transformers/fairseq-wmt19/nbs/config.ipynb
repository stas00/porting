{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/code/huggingface/transformers-fair-wmt/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n",
    "import fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_state_keys(state_dict): print(\"\\n\".join(state_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq import hub_utils\n",
    "#checkpoint_file = 'model1.pt:model2.pt:model3.pt:model4.pt'\n",
    "checkpoint_file = 'model1.pt'\n",
    "model_name_or_path = 'transformer.wmt19.ru-en'\n",
    "data_name_or_path = '.'\n",
    "cls = fairseq.model_parallel.models.transformer.ModelParallelTransformerModel\n",
    "models = cls.hub_models()\n",
    "kwargs = {'bpe': 'fastbpe', 'tokenizer': 'moses'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru2en = hub_utils.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            checkpoint_file,\n",
    "            data_name_or_path,\n",
    "            archive_map=models,\n",
    "            **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt'\n",
    "# path = \"/code/huggingface/transformers-fair-wmt\"\n",
    "# mname = 'transformer.wmt19.ru-en'\n",
    "# chkpt1_path = path + \"/data/wmt19.ru-en.ensemble/model4.pt\"\n",
    "# checkpoint_file='model1.pt'\n",
    "\n",
    "# chkpt = torch.load(chkpt1_path, map_location=\"cpu\")\n",
    "\n",
    "\n",
    "# validate that the model keys are correct:\n",
    "#hub_interface = torch.hub.load(\"pytorch/fairseq\", mname, checkpoint_file).eval()\n",
    "#hub_interface.models[0].load_state_dict(chkpt[\"model\"])\n",
    "#chkpt = hub_interface\n",
    "\n",
    "# this works just as well, but the above validates that the local copy loads correctly\n",
    "# chkpt = torch.load(chkpt1_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chkpt.models[0].upgrade_state_dict(chkpt.models[0].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ru2en[\"models\"][0]\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(vars(ru2en[\"args\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ru'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args[\"source_lang\"]\n",
    "args[\"encoder_embed_dim\"]\n",
    "args[\"decoder_embed_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation_dropout': 0.0,\n",
      " 'activation_fn': 'relu',\n",
      " 'adam_betas': '(0.9, 0.98)',\n",
      " 'adam_eps': 1e-08,\n",
      " 'adaptive_input': False,\n",
      " 'adaptive_softmax_cutoff': None,\n",
      " 'adaptive_softmax_dropout': 0,\n",
      " 'arch': 'transformer_wmt_en_de_big',\n",
      " 'attention_dropout': 0.1,\n",
      " 'bpe': 'fastbpe',\n",
      " 'bpe_codes': '/home/stas/.cache/torch/pytorch_fairseq/1f635f61a93197b2be015bcdc60f47829db1172b5b81547d72b7b28235b28fa9.5e1a2ea19b51d6733a96ed885e05dc2d3d1e3cb3573b9e62ee7acfb0454ee976/bpecodes',\n",
      " 'bucket_cap_mb': 25,\n",
      " 'clip_norm': 0.0,\n",
      " 'cpu': False,\n",
      " 'criterion': 'label_smoothed_cross_entropy',\n",
      " 'cross_self_attention': False,\n",
      " 'data': '/home/stas/.cache/torch/pytorch_fairseq/1f635f61a93197b2be015bcdc60f47829db1172b5b81547d72b7b28235b28fa9.5e1a2ea19b51d6733a96ed885e05dc2d3d1e3cb3573b9e62ee7acfb0454ee976',\n",
      " 'ddp_backend': 'c10d',\n",
      " 'decoder_attention_heads': 16,\n",
      " 'decoder_embed_dim': 1024,\n",
      " 'decoder_embed_path': None,\n",
      " 'decoder_ffn_embed_dim': 4096,\n",
      " 'decoder_input_dim': 1024,\n",
      " 'decoder_layerdrop': 0,\n",
      " 'decoder_layers': 6,\n",
      " 'decoder_layers_to_keep': None,\n",
      " 'decoder_learned_pos': False,\n",
      " 'decoder_normalize_before': False,\n",
      " 'decoder_output_dim': 1024,\n",
      " 'device_id': 0,\n",
      " 'distributed_backend': 'nccl',\n",
      " 'distributed_init_method': 'tcp://localhost:15993',\n",
      " 'distributed_port': -1,\n",
      " 'distributed_rank': 0,\n",
      " 'distributed_world_size': 2,\n",
      " 'dropout': 0.2,\n",
      " 'encoder_attention_heads': 16,\n",
      " 'encoder_embed_dim': 1024,\n",
      " 'encoder_embed_path': None,\n",
      " 'encoder_ffn_embed_dim': 8192,\n",
      " 'encoder_layerdrop': 0,\n",
      " 'encoder_layers': 6,\n",
      " 'encoder_layers_to_keep': None,\n",
      " 'encoder_learned_pos': False,\n",
      " 'encoder_normalize_before': False,\n",
      " 'eval_bleu_detok': 'space',\n",
      " 'eval_bleu_remove_bpe': None,\n",
      " 'eval_tokenized_bleu': False,\n",
      " 'extra_data': '',\n",
      " 'fix_batches_to_gpus': False,\n",
      " 'fp16': True,\n",
      " 'fp16_init_scale': 128,\n",
      " 'fp16_scale_tolerance': 0.0,\n",
      " 'fp16_scale_window': None,\n",
      " 'keep_interval_updates': -1,\n",
      " 'keep_last_epochs': -1,\n",
      " 'label_smoothing': 0.1,\n",
      " 'layernorm_embedding': False,\n",
      " 'lazy_load': False,\n",
      " 'left_pad_source': False,\n",
      " 'left_pad_target': False,\n",
      " 'log_format': 'simple',\n",
      " 'log_interval': 100,\n",
      " 'lr': [0.0007],\n",
      " 'lr_scheduler': 'inverse_sqrt',\n",
      " 'lr_shrink': 0.1,\n",
      " 'max_epoch': 0,\n",
      " 'max_sentences': None,\n",
      " 'max_sentences_valid': None,\n",
      " 'max_source_positions': 1024,\n",
      " 'max_target_positions': 1024,\n",
      " 'max_tokens': 3584,\n",
      " 'max_update': 201700,\n",
      " 'memory_efficient_fp16': False,\n",
      " 'min_loss_scale': 0.0001,\n",
      " 'min_lr': 1e-09,\n",
      " 'momentum': 0.99,\n",
      " 'moses_no_dash_splits': False,\n",
      " 'moses_no_escape': False,\n",
      " 'no_cross_attention': False,\n",
      " 'no_epoch_checkpoints': False,\n",
      " 'no_progress_bar': True,\n",
      " 'no_save': False,\n",
      " 'no_scale_embedding': False,\n",
      " 'no_token_positional_embeddings': False,\n",
      " 'num_batch_buckets': 0,\n",
      " 'num_workers': 0,\n",
      " 'optimizer': 'adam',\n",
      " 'optimizer_overrides': '{}',\n",
      " 'quant_noise_pq': 0,\n",
      " 'quant_noise_pq_block_size': 8,\n",
      " 'quant_noise_scalar': 0,\n",
      " 'raw_text': False,\n",
      " 'relu_dropout': 0.0,\n",
      " 'reset_lr_scheduler': False,\n",
      " 'reset_optimizer': False,\n",
      " 'restore_file': 'checkpoint_last.pt',\n",
      " 'save_dir': '/checkpoint/edunov/20190403/wmt19ru2en.btsample5.ffn8192.transformer_wmt_en_de_big_bsz3584_lr0.0007_dr0.2_size_updates200000_seed2_lbsm0.1_size_sa0_upsample2/finetune/',\n",
      " 'save_interval': 1,\n",
      " 'save_interval_updates': 200,\n",
      " 'seed': 2,\n",
      " 'sentence_avg': False,\n",
      " 'share_all_embeddings': False,\n",
      " 'share_decoder_input_output_embed': True,\n",
      " 'skip_invalid_size_inputs_valid_test': False,\n",
      " 'source_lang': 'ru',\n",
      " 'target_lang': 'en',\n",
      " 'task': 'translation',\n",
      " 'tensorboard_logdir': '',\n",
      " 'threshold_loss_scale': None,\n",
      " 'tie_adaptive_weights': False,\n",
      " 'tokenizer': 'moses',\n",
      " 'train_subset': 'train',\n",
      " 'truncate_source': False,\n",
      " 'update_freq': [1],\n",
      " 'upsample_primary': 4,\n",
      " 'use_old_adam': False,\n",
      " 'user_dir': None,\n",
      " 'valid_subset': 'valid',\n",
      " 'validate_interval': 1,\n",
      " 'warmup_init_lr': 1e-07,\n",
      " 'warmup_updates': 4000,\n",
      " 'weight_decay': 0.0}\n"
     ]
    }
   ],
   "source": [
    "pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['no_progress_bar', 'log_interval', 'log_format', 'tensorboard_logdir', 'seed', 'cpu', 'fp16', 'memory_efficient_fp16', 'fp16_init_scale', 'fp16_scale_window', 'fp16_scale_tolerance', 'min_loss_scale', 'threshold_loss_scale', 'user_dir', 'task', 'num_workers', 'skip_invalid_size_inputs_valid_test', 'max_tokens', 'max_sentences', 'train_subset', 'valid_subset', 'max_sentences_valid', 'distributed_world_size', 'distributed_rank', 'distributed_backend', 'distributed_init_method', 'distributed_port', 'device_id', 'ddp_backend', 'bucket_cap_mb', 'fix_batches_to_gpus', 'arch', 'criterion', 'max_epoch', 'max_update', 'clip_norm', 'sentence_avg', 'update_freq', 'optimizer', 'lr', 'momentum', 'weight_decay', 'lr_scheduler', 'lr_shrink', 'min_lr', 'save_dir', 'restore_file', 'reset_optimizer', 'reset_lr_scheduler', 'optimizer_overrides', 'save_interval', 'save_interval_updates', 'keep_interval_updates', 'keep_last_epochs', 'no_save', 'no_epoch_checkpoints', 'validate_interval', 'no_token_positional_embeddings', 'label_smoothing', 'adam_betas', 'adam_eps', 'warmup_updates', 'warmup_init_lr', 'data', 'extra_data', 'source_lang', 'target_lang', 'lazy_load', 'raw_text', 'left_pad_source', 'left_pad_target', 'max_source_positions', 'max_target_positions', 'upsample_primary', 'share_decoder_input_output_embed', 'dropout', 'encoder_ffn_embed_dim', 'attention_dropout', 'encoder_embed_dim', 'encoder_attention_heads', 'encoder_normalize_before', 'decoder_embed_dim', 'decoder_ffn_embed_dim', 'decoder_attention_heads', 'encoder_embed_path', 'encoder_layers', 'encoder_learned_pos', 'decoder_embed_path', 'decoder_layers', 'decoder_normalize_before', 'decoder_learned_pos', 'relu_dropout', 'adaptive_softmax_cutoff', 'adaptive_softmax_dropout', 'share_all_embeddings', 'adaptive_input', 'decoder_output_dim', 'decoder_input_dim', 'bpe', 'tokenizer', 'bpe_codes', 'truncate_source', 'num_batch_buckets', 'eval_bleu_detok', 'eval_tokenized_bleu', 'eval_bleu_remove_bpe', 'no_cross_attention', 'cross_self_attention', 'encoder_layerdrop', 'decoder_layerdrop', 'encoder_layers_to_keep', 'decoder_layers_to_keep', 'quant_noise_pq', 'quant_noise_pq_block_size', 'quant_noise_scalar', 'moses_no_dash_splits', 'moses_no_escape', 'use_old_adam', 'activation_dropout', 'activation_fn', 'no_scale_embedding', 'layernorm_embedding', 'tie_adaptive_weights'])\n"
     ]
    }
   ],
   "source": [
    "pprint(args.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.state_dict()\n",
    "#model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.version\n",
      "encoder.embed_tokens.weight\n",
      "encoder.embed_positions._float_tensor\n",
      "encoder.layers.0.self_attn.k_proj.weight\n",
      "encoder.layers.0.self_attn.k_proj.bias\n",
      "encoder.layers.0.self_attn.v_proj.weight\n",
      "encoder.layers.0.self_attn.v_proj.bias\n",
      "encoder.layers.0.self_attn.q_proj.weight\n",
      "encoder.layers.0.self_attn.q_proj.bias\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "encoder.layers.0.self_attn_layer_norm.weight\n",
      "encoder.layers.0.self_attn_layer_norm.bias\n",
      "encoder.layers.0.fc1.weight\n",
      "encoder.layers.0.fc1.bias\n",
      "encoder.layers.0.fc2.weight\n",
      "encoder.layers.0.fc2.bias\n",
      "encoder.layers.0.final_layer_norm.weight\n",
      "encoder.layers.0.final_layer_norm.bias\n",
      "encoder.layers.1.self_attn.k_proj.weight\n",
      "encoder.layers.1.self_attn.k_proj.bias\n",
      "encoder.layers.1.self_attn.v_proj.weight\n",
      "encoder.layers.1.self_attn.v_proj.bias\n",
      "encoder.layers.1.self_attn.q_proj.weight\n",
      "encoder.layers.1.self_attn.q_proj.bias\n",
      "encoder.layers.1.self_attn.out_proj.weight\n",
      "encoder.layers.1.self_attn.out_proj.bias\n",
      "encoder.layers.1.self_attn_layer_norm.weight\n",
      "encoder.layers.1.self_attn_layer_norm.bias\n",
      "encoder.layers.1.fc1.weight\n",
      "encoder.layers.1.fc1.bias\n",
      "encoder.layers.1.fc2.weight\n",
      "encoder.layers.1.fc2.bias\n",
      "encoder.layers.1.final_layer_norm.weight\n",
      "encoder.layers.1.final_layer_norm.bias\n",
      "encoder.layers.2.self_attn.k_proj.weight\n",
      "encoder.layers.2.self_attn.k_proj.bias\n",
      "encoder.layers.2.self_attn.v_proj.weight\n",
      "encoder.layers.2.self_attn.v_proj.bias\n",
      "encoder.layers.2.self_attn.q_proj.weight\n",
      "encoder.layers.2.self_attn.q_proj.bias\n",
      "encoder.layers.2.self_attn.out_proj.weight\n",
      "encoder.layers.2.self_attn.out_proj.bias\n",
      "encoder.layers.2.self_attn_layer_norm.weight\n",
      "encoder.layers.2.self_attn_layer_norm.bias\n",
      "encoder.layers.2.fc1.weight\n",
      "encoder.layers.2.fc1.bias\n",
      "encoder.layers.2.fc2.weight\n",
      "encoder.layers.2.fc2.bias\n",
      "encoder.layers.2.final_layer_norm.weight\n",
      "encoder.layers.2.final_layer_norm.bias\n",
      "encoder.layers.3.self_attn.k_proj.weight\n",
      "encoder.layers.3.self_attn.k_proj.bias\n",
      "encoder.layers.3.self_attn.v_proj.weight\n",
      "encoder.layers.3.self_attn.v_proj.bias\n",
      "encoder.layers.3.self_attn.q_proj.weight\n",
      "encoder.layers.3.self_attn.q_proj.bias\n",
      "encoder.layers.3.self_attn.out_proj.weight\n",
      "encoder.layers.3.self_attn.out_proj.bias\n",
      "encoder.layers.3.self_attn_layer_norm.weight\n",
      "encoder.layers.3.self_attn_layer_norm.bias\n",
      "encoder.layers.3.fc1.weight\n",
      "encoder.layers.3.fc1.bias\n",
      "encoder.layers.3.fc2.weight\n",
      "encoder.layers.3.fc2.bias\n",
      "encoder.layers.3.final_layer_norm.weight\n",
      "encoder.layers.3.final_layer_norm.bias\n",
      "encoder.layers.4.self_attn.k_proj.weight\n",
      "encoder.layers.4.self_attn.k_proj.bias\n",
      "encoder.layers.4.self_attn.v_proj.weight\n",
      "encoder.layers.4.self_attn.v_proj.bias\n",
      "encoder.layers.4.self_attn.q_proj.weight\n",
      "encoder.layers.4.self_attn.q_proj.bias\n",
      "encoder.layers.4.self_attn.out_proj.weight\n",
      "encoder.layers.4.self_attn.out_proj.bias\n",
      "encoder.layers.4.self_attn_layer_norm.weight\n",
      "encoder.layers.4.self_attn_layer_norm.bias\n",
      "encoder.layers.4.fc1.weight\n",
      "encoder.layers.4.fc1.bias\n",
      "encoder.layers.4.fc2.weight\n",
      "encoder.layers.4.fc2.bias\n",
      "encoder.layers.4.final_layer_norm.weight\n",
      "encoder.layers.4.final_layer_norm.bias\n",
      "encoder.layers.5.self_attn.k_proj.weight\n",
      "encoder.layers.5.self_attn.k_proj.bias\n",
      "encoder.layers.5.self_attn.v_proj.weight\n",
      "encoder.layers.5.self_attn.v_proj.bias\n",
      "encoder.layers.5.self_attn.q_proj.weight\n",
      "encoder.layers.5.self_attn.q_proj.bias\n",
      "encoder.layers.5.self_attn.out_proj.weight\n",
      "encoder.layers.5.self_attn.out_proj.bias\n",
      "encoder.layers.5.self_attn_layer_norm.weight\n",
      "encoder.layers.5.self_attn_layer_norm.bias\n",
      "encoder.layers.5.fc1.weight\n",
      "encoder.layers.5.fc1.bias\n",
      "encoder.layers.5.fc2.weight\n",
      "encoder.layers.5.fc2.bias\n",
      "encoder.layers.5.final_layer_norm.weight\n",
      "encoder.layers.5.final_layer_norm.bias\n",
      "decoder.version\n",
      "decoder.embed_tokens.weight\n",
      "decoder.embed_positions._float_tensor\n",
      "decoder.layers.0.self_attn.k_proj.weight\n",
      "decoder.layers.0.self_attn.k_proj.bias\n",
      "decoder.layers.0.self_attn.v_proj.weight\n",
      "decoder.layers.0.self_attn.v_proj.bias\n",
      "decoder.layers.0.self_attn.q_proj.weight\n",
      "decoder.layers.0.self_attn.q_proj.bias\n",
      "decoder.layers.0.self_attn.out_proj.weight\n",
      "decoder.layers.0.self_attn.out_proj.bias\n",
      "decoder.layers.0.self_attn_layer_norm.weight\n",
      "decoder.layers.0.self_attn_layer_norm.bias\n",
      "decoder.layers.0.encoder_attn.k_proj.weight\n",
      "decoder.layers.0.encoder_attn.k_proj.bias\n",
      "decoder.layers.0.encoder_attn.v_proj.weight\n",
      "decoder.layers.0.encoder_attn.v_proj.bias\n",
      "decoder.layers.0.encoder_attn.q_proj.weight\n",
      "decoder.layers.0.encoder_attn.q_proj.bias\n",
      "decoder.layers.0.encoder_attn.out_proj.weight\n",
      "decoder.layers.0.encoder_attn.out_proj.bias\n",
      "decoder.layers.0.encoder_attn_layer_norm.weight\n",
      "decoder.layers.0.encoder_attn_layer_norm.bias\n",
      "decoder.layers.0.fc1.weight\n",
      "decoder.layers.0.fc1.bias\n",
      "decoder.layers.0.fc2.weight\n",
      "decoder.layers.0.fc2.bias\n",
      "decoder.layers.0.final_layer_norm.weight\n",
      "decoder.layers.0.final_layer_norm.bias\n",
      "decoder.layers.1.self_attn.k_proj.weight\n",
      "decoder.layers.1.self_attn.k_proj.bias\n",
      "decoder.layers.1.self_attn.v_proj.weight\n",
      "decoder.layers.1.self_attn.v_proj.bias\n",
      "decoder.layers.1.self_attn.q_proj.weight\n",
      "decoder.layers.1.self_attn.q_proj.bias\n",
      "decoder.layers.1.self_attn.out_proj.weight\n",
      "decoder.layers.1.self_attn.out_proj.bias\n",
      "decoder.layers.1.self_attn_layer_norm.weight\n",
      "decoder.layers.1.self_attn_layer_norm.bias\n",
      "decoder.layers.1.encoder_attn.k_proj.weight\n",
      "decoder.layers.1.encoder_attn.k_proj.bias\n",
      "decoder.layers.1.encoder_attn.v_proj.weight\n",
      "decoder.layers.1.encoder_attn.v_proj.bias\n",
      "decoder.layers.1.encoder_attn.q_proj.weight\n",
      "decoder.layers.1.encoder_attn.q_proj.bias\n",
      "decoder.layers.1.encoder_attn.out_proj.weight\n",
      "decoder.layers.1.encoder_attn.out_proj.bias\n",
      "decoder.layers.1.encoder_attn_layer_norm.weight\n",
      "decoder.layers.1.encoder_attn_layer_norm.bias\n",
      "decoder.layers.1.fc1.weight\n",
      "decoder.layers.1.fc1.bias\n",
      "decoder.layers.1.fc2.weight\n",
      "decoder.layers.1.fc2.bias\n",
      "decoder.layers.1.final_layer_norm.weight\n",
      "decoder.layers.1.final_layer_norm.bias\n",
      "decoder.layers.2.self_attn.k_proj.weight\n",
      "decoder.layers.2.self_attn.k_proj.bias\n",
      "decoder.layers.2.self_attn.v_proj.weight\n",
      "decoder.layers.2.self_attn.v_proj.bias\n",
      "decoder.layers.2.self_attn.q_proj.weight\n",
      "decoder.layers.2.self_attn.q_proj.bias\n",
      "decoder.layers.2.self_attn.out_proj.weight\n",
      "decoder.layers.2.self_attn.out_proj.bias\n",
      "decoder.layers.2.self_attn_layer_norm.weight\n",
      "decoder.layers.2.self_attn_layer_norm.bias\n",
      "decoder.layers.2.encoder_attn.k_proj.weight\n",
      "decoder.layers.2.encoder_attn.k_proj.bias\n",
      "decoder.layers.2.encoder_attn.v_proj.weight\n",
      "decoder.layers.2.encoder_attn.v_proj.bias\n",
      "decoder.layers.2.encoder_attn.q_proj.weight\n",
      "decoder.layers.2.encoder_attn.q_proj.bias\n",
      "decoder.layers.2.encoder_attn.out_proj.weight\n",
      "decoder.layers.2.encoder_attn.out_proj.bias\n",
      "decoder.layers.2.encoder_attn_layer_norm.weight\n",
      "decoder.layers.2.encoder_attn_layer_norm.bias\n",
      "decoder.layers.2.fc1.weight\n",
      "decoder.layers.2.fc1.bias\n",
      "decoder.layers.2.fc2.weight\n",
      "decoder.layers.2.fc2.bias\n",
      "decoder.layers.2.final_layer_norm.weight\n",
      "decoder.layers.2.final_layer_norm.bias\n",
      "decoder.layers.3.self_attn.k_proj.weight\n",
      "decoder.layers.3.self_attn.k_proj.bias\n",
      "decoder.layers.3.self_attn.v_proj.weight\n",
      "decoder.layers.3.self_attn.v_proj.bias\n",
      "decoder.layers.3.self_attn.q_proj.weight\n",
      "decoder.layers.3.self_attn.q_proj.bias\n",
      "decoder.layers.3.self_attn.out_proj.weight\n",
      "decoder.layers.3.self_attn.out_proj.bias\n",
      "decoder.layers.3.self_attn_layer_norm.weight\n",
      "decoder.layers.3.self_attn_layer_norm.bias\n",
      "decoder.layers.3.encoder_attn.k_proj.weight\n",
      "decoder.layers.3.encoder_attn.k_proj.bias\n",
      "decoder.layers.3.encoder_attn.v_proj.weight\n",
      "decoder.layers.3.encoder_attn.v_proj.bias\n",
      "decoder.layers.3.encoder_attn.q_proj.weight\n",
      "decoder.layers.3.encoder_attn.q_proj.bias\n",
      "decoder.layers.3.encoder_attn.out_proj.weight\n",
      "decoder.layers.3.encoder_attn.out_proj.bias\n",
      "decoder.layers.3.encoder_attn_layer_norm.weight\n",
      "decoder.layers.3.encoder_attn_layer_norm.bias\n",
      "decoder.layers.3.fc1.weight\n",
      "decoder.layers.3.fc1.bias\n",
      "decoder.layers.3.fc2.weight\n",
      "decoder.layers.3.fc2.bias\n",
      "decoder.layers.3.final_layer_norm.weight\n",
      "decoder.layers.3.final_layer_norm.bias\n",
      "decoder.layers.4.self_attn.k_proj.weight\n",
      "decoder.layers.4.self_attn.k_proj.bias\n",
      "decoder.layers.4.self_attn.v_proj.weight\n",
      "decoder.layers.4.self_attn.v_proj.bias\n",
      "decoder.layers.4.self_attn.q_proj.weight\n",
      "decoder.layers.4.self_attn.q_proj.bias\n",
      "decoder.layers.4.self_attn.out_proj.weight\n",
      "decoder.layers.4.self_attn.out_proj.bias\n",
      "decoder.layers.4.self_attn_layer_norm.weight\n",
      "decoder.layers.4.self_attn_layer_norm.bias\n",
      "decoder.layers.4.encoder_attn.k_proj.weight\n",
      "decoder.layers.4.encoder_attn.k_proj.bias\n",
      "decoder.layers.4.encoder_attn.v_proj.weight\n",
      "decoder.layers.4.encoder_attn.v_proj.bias\n",
      "decoder.layers.4.encoder_attn.q_proj.weight\n",
      "decoder.layers.4.encoder_attn.q_proj.bias\n",
      "decoder.layers.4.encoder_attn.out_proj.weight\n",
      "decoder.layers.4.encoder_attn.out_proj.bias\n",
      "decoder.layers.4.encoder_attn_layer_norm.weight\n",
      "decoder.layers.4.encoder_attn_layer_norm.bias\n",
      "decoder.layers.4.fc1.weight\n",
      "decoder.layers.4.fc1.bias\n",
      "decoder.layers.4.fc2.weight\n",
      "decoder.layers.4.fc2.bias\n",
      "decoder.layers.4.final_layer_norm.weight\n",
      "decoder.layers.4.final_layer_norm.bias\n",
      "decoder.layers.5.self_attn.k_proj.weight\n",
      "decoder.layers.5.self_attn.k_proj.bias\n",
      "decoder.layers.5.self_attn.v_proj.weight\n",
      "decoder.layers.5.self_attn.v_proj.bias\n",
      "decoder.layers.5.self_attn.q_proj.weight\n",
      "decoder.layers.5.self_attn.q_proj.bias\n",
      "decoder.layers.5.self_attn.out_proj.weight\n",
      "decoder.layers.5.self_attn.out_proj.bias\n",
      "decoder.layers.5.self_attn_layer_norm.weight\n",
      "decoder.layers.5.self_attn_layer_norm.bias\n",
      "decoder.layers.5.encoder_attn.k_proj.weight\n",
      "decoder.layers.5.encoder_attn.k_proj.bias\n",
      "decoder.layers.5.encoder_attn.v_proj.weight\n",
      "decoder.layers.5.encoder_attn.v_proj.bias\n",
      "decoder.layers.5.encoder_attn.q_proj.weight\n",
      "decoder.layers.5.encoder_attn.q_proj.bias\n",
      "decoder.layers.5.encoder_attn.out_proj.weight\n",
      "decoder.layers.5.encoder_attn.out_proj.bias\n",
      "decoder.layers.5.encoder_attn_layer_norm.weight\n",
      "decoder.layers.5.encoder_attn_layer_norm.bias\n",
      "decoder.layers.5.fc1.weight\n",
      "decoder.layers.5.fc1.bias\n",
      "decoder.layers.5.fc2.weight\n",
      "decoder.layers.5.fc2.bias\n",
      "decoder.layers.5.final_layer_norm.weight\n",
      "decoder.layers.5.final_layer_norm.bias\n",
      "decoder.output_projection.weight\n"
     ]
    }
   ],
   "source": [
    "#model = dict(vars(model))\n",
    "dump_state_keys(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.items()\n",
    "model_state_dict[\"decoder.layers.5.fc2.bias\"].shape.numel()\n",
    "model_state_dict[\"decoder.layers.5.fc2.bias\"].shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['           1 encoder.version',\n",
      " '  31232 1024 encoder.embed_tokens.weight',\n",
      " '           1 encoder.embed_positions._float_tensor',\n",
      " '   1024 1024 encoder.layers.0.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.0.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.0.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.0.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.0.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.0.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.0.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.0.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.0.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.0.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.0.fc1.weight',\n",
      " '        8192 encoder.layers.0.fc1.bias',\n",
      " '   1024 8192 encoder.layers.0.fc2.weight',\n",
      " '        1024 encoder.layers.0.fc2.bias',\n",
      " '        1024 encoder.layers.0.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.0.final_layer_norm.bias',\n",
      " '   1024 1024 encoder.layers.1.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.1.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.1.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.1.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.1.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.1.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.1.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.1.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.1.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.1.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.1.fc1.weight',\n",
      " '        8192 encoder.layers.1.fc1.bias',\n",
      " '   1024 8192 encoder.layers.1.fc2.weight',\n",
      " '        1024 encoder.layers.1.fc2.bias',\n",
      " '        1024 encoder.layers.1.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.1.final_layer_norm.bias',\n",
      " '   1024 1024 encoder.layers.2.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.2.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.2.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.2.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.2.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.2.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.2.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.2.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.2.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.2.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.2.fc1.weight',\n",
      " '        8192 encoder.layers.2.fc1.bias',\n",
      " '   1024 8192 encoder.layers.2.fc2.weight',\n",
      " '        1024 encoder.layers.2.fc2.bias',\n",
      " '        1024 encoder.layers.2.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.2.final_layer_norm.bias',\n",
      " '   1024 1024 encoder.layers.3.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.3.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.3.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.3.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.3.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.3.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.3.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.3.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.3.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.3.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.3.fc1.weight',\n",
      " '        8192 encoder.layers.3.fc1.bias',\n",
      " '   1024 8192 encoder.layers.3.fc2.weight',\n",
      " '        1024 encoder.layers.3.fc2.bias',\n",
      " '        1024 encoder.layers.3.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.3.final_layer_norm.bias',\n",
      " '   1024 1024 encoder.layers.4.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.4.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.4.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.4.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.4.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.4.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.4.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.4.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.4.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.4.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.4.fc1.weight',\n",
      " '        8192 encoder.layers.4.fc1.bias',\n",
      " '   1024 8192 encoder.layers.4.fc2.weight',\n",
      " '        1024 encoder.layers.4.fc2.bias',\n",
      " '        1024 encoder.layers.4.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.4.final_layer_norm.bias',\n",
      " '   1024 1024 encoder.layers.5.self_attn.k_proj.weight',\n",
      " '        1024 encoder.layers.5.self_attn.k_proj.bias',\n",
      " '   1024 1024 encoder.layers.5.self_attn.v_proj.weight',\n",
      " '        1024 encoder.layers.5.self_attn.v_proj.bias',\n",
      " '   1024 1024 encoder.layers.5.self_attn.q_proj.weight',\n",
      " '        1024 encoder.layers.5.self_attn.q_proj.bias',\n",
      " '   1024 1024 encoder.layers.5.self_attn.out_proj.weight',\n",
      " '        1024 encoder.layers.5.self_attn.out_proj.bias',\n",
      " '        1024 encoder.layers.5.self_attn_layer_norm.weight',\n",
      " '        1024 encoder.layers.5.self_attn_layer_norm.bias',\n",
      " '   8192 1024 encoder.layers.5.fc1.weight',\n",
      " '        8192 encoder.layers.5.fc1.bias',\n",
      " '   1024 8192 encoder.layers.5.fc2.weight',\n",
      " '        1024 encoder.layers.5.fc2.bias',\n",
      " '        1024 encoder.layers.5.final_layer_norm.weight',\n",
      " '        1024 encoder.layers.5.final_layer_norm.bias',\n",
      " '           1 decoder.version',\n",
      " '  31640 1024 decoder.embed_tokens.weight',\n",
      " '           1 decoder.embed_positions._float_tensor',\n",
      " '   1024 1024 decoder.layers.0.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.0.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.0.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.0.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.0.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.0.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.0.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.0.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.0.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.0.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.0.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.0.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.0.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.0.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.0.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.0.fc1.weight',\n",
      " '        4096 decoder.layers.0.fc1.bias',\n",
      " '   1024 4096 decoder.layers.0.fc2.weight',\n",
      " '        1024 decoder.layers.0.fc2.bias',\n",
      " '        1024 decoder.layers.0.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.0.final_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.1.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.1.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.1.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.1.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.1.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.1.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.1.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.1.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.1.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.1.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.1.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.1.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.1.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.1.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.1.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.1.fc1.weight',\n",
      " '        4096 decoder.layers.1.fc1.bias',\n",
      " '   1024 4096 decoder.layers.1.fc2.weight',\n",
      " '        1024 decoder.layers.1.fc2.bias',\n",
      " '        1024 decoder.layers.1.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.1.final_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.2.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.2.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.2.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.2.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.2.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.2.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.2.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.2.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.2.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.2.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.2.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.2.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.2.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.2.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.2.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.2.fc1.weight',\n",
      " '        4096 decoder.layers.2.fc1.bias',\n",
      " '   1024 4096 decoder.layers.2.fc2.weight',\n",
      " '        1024 decoder.layers.2.fc2.bias',\n",
      " '        1024 decoder.layers.2.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.2.final_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.3.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.3.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.3.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.3.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.3.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.3.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.3.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.3.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.3.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.3.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.3.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.3.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.3.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.3.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.3.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.3.fc1.weight',\n",
      " '        4096 decoder.layers.3.fc1.bias',\n",
      " '   1024 4096 decoder.layers.3.fc2.weight',\n",
      " '        1024 decoder.layers.3.fc2.bias',\n",
      " '        1024 decoder.layers.3.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.3.final_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.4.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.4.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.4.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.4.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.4.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.4.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.4.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.4.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.4.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.4.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.4.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.4.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.4.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.4.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.4.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.4.fc1.weight',\n",
      " '        4096 decoder.layers.4.fc1.bias',\n",
      " '   1024 4096 decoder.layers.4.fc2.weight',\n",
      " '        1024 decoder.layers.4.fc2.bias',\n",
      " '        1024 decoder.layers.4.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.4.final_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.5.self_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.5.self_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.self_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.5.self_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.self_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.5.self_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.self_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.5.self_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.5.self_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.5.self_attn_layer_norm.bias',\n",
      " '   1024 1024 decoder.layers.5.encoder_attn.k_proj.weight',\n",
      " '        1024 decoder.layers.5.encoder_attn.k_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.encoder_attn.v_proj.weight',\n",
      " '        1024 decoder.layers.5.encoder_attn.v_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.encoder_attn.q_proj.weight',\n",
      " '        1024 decoder.layers.5.encoder_attn.q_proj.bias',\n",
      " '   1024 1024 decoder.layers.5.encoder_attn.out_proj.weight',\n",
      " '        1024 decoder.layers.5.encoder_attn.out_proj.bias',\n",
      " '        1024 decoder.layers.5.encoder_attn_layer_norm.weight',\n",
      " '        1024 decoder.layers.5.encoder_attn_layer_norm.bias',\n",
      " '   4096 1024 decoder.layers.5.fc1.weight',\n",
      " '        4096 decoder.layers.5.fc1.bias',\n",
      " '   1024 4096 decoder.layers.5.fc2.weight',\n",
      " '        1024 decoder.layers.5.fc2.bias',\n",
      " '        1024 decoder.layers.5.final_layer_norm.weight',\n",
      " '        1024 decoder.layers.5.final_layer_norm.bias',\n",
      " '  31640 1024 decoder.output_projection.weight']\n"
     ]
    }
   ],
   "source": [
    "# dump the state_dict attrs and their shape\n",
    "pprint([f\"{' '.join(map(str, v.shape)):>12} {k}\"for k,v in model_state_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renames/removal\n",
    "from collections import OrderedDict\n",
    "\n",
    "rename_keys = [\n",
    "#    (\"model.encoder.embed_positions._float_tensor\", \"model.encoder.embed_positions.weight\"),\n",
    "#    (\"model.decoder.embed_positions._float_tensor\", \"model.decoder.embed_positions.weight\"),\n",
    "#    (\"\", \"\"),\n",
    "#    (\"\", \"\"),\n",
    "#    (\"\", \"\"),\n",
    "#    (\"\", \"\"),    \n",
    "]\n",
    "\n",
    "def remove_ignore_keys_(model_state_dict):\n",
    "    ignore_keys = [\n",
    "        \"model.model\",\n",
    "        \"model.encoder.version\",\n",
    "        \"model.decoder.version\",\n",
    "        \"model.encoder.embed_positions._float_tensor\", # not storing model.encoder.embed_positions.weight\n",
    "        \"model.decoder.embed_positions._float_tensor\", # not storing model.decoder.embed_positions.weight\n",
    "    ]\n",
    "    for k in ignore_keys:\n",
    "        model_state_dict.pop(k, None)\n",
    "\n",
    "def rename_key(dct, old, new):\n",
    "    val = dct.pop(old)\n",
    "    dct[new] = val\n",
    "\n",
    "#model_state_dict = chkpt[\"model\"].copy()\n",
    "\n",
    "# rename keys to start with model.\n",
    "model_state_dict_new = OrderedDict((\"model.\"+k, v) for k, v in model_state_dict.items())\n",
    "# check:\n",
    "#model_state_dict[\"model.encoder.layers.0.fc1.bias\"]\n",
    "#chkpt[\"model\"][\"encoder.layers.0.fc1.bias\"]\n",
    "    \n",
    "remove_ignore_keys_(model_state_dict_new)\n",
    "for src, dest in rename_keys:\n",
    "    rename_key(model_state_dict_new, src, dest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31640, 1024])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict_new[\"model.decoder.embed_tokens.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31640])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emulate non-existing layer - perhaps it'll be removed instead in the model - for now just a bias of 0's\n",
    "model_state_dict_new[\"final_logits_bias\"] = torch.zeros((1, model_state_dict_new[\"model.decoder.embed_tokens.weight\"].shape[0])) \n",
    "                                                        \n",
    "model_state_dict_new[\"final_logits_bias\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#pprint(state_dict.keys())\n",
    "#state_dict[\"model.encoder.layers.0.fc1.bias\"]\n",
    "#state_dict[\"model.encoder.embed_positions.weight\"]\n",
    "#torch.FloatTensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_fsmt import FSMTForConditionalGeneration\n",
    "from transformers.configuration_fsmt import FSMTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "hf_checkpoint_name = \"/code/huggingface/transformers-fair-wmt/data/wmt19-ru-en/config.json\"\n",
    "config = FSMTConfig.from_pretrained(hf_checkpoint_name)\n",
    "model_new = FSMTForConditionalGeneration(config).eval()\n",
    "#state_dict = chkpt[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31640, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump_state_keys(model_state_dict_new)\n",
    "model_state_dict_new[\"model.decoder.embed_tokens.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([31232, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([31640, 1024])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's add dummy things so that load_state_dict doesn't complain\n",
    "# (embed_positions): SinusoidalPositionalEmbedding(1024, 1024)\n",
    "# XXX: these seem to be autogenerated on the fly, no need to store\n",
    "model_state_dict_new[\"model.encoder.embed_positions.weight\"] = model_state_dict_new[\"model.decoder.embed_positions.weight\"] = torch.zeros((args[\"decoder_input_dim\"], args[\"decoder_input_dim\"]))\n",
    "\n",
    "model_state_dict_new[\"model.encoder.embed_positions.weight\"].shape\n",
    "model_state_dict_new[\"model.decoder.embed_positions.weight\"].shape\n",
    "\n",
    "# these too get autogenerated:\n",
    "# \"model.encoder_embed_tokens.weight\",\n",
    "# \"model.decoder_embed_tokens.weight\",\n",
    "\n",
    "# encoder_emd_tok_dim\n",
    "args[\"encoder_emd_tok_dim\"] = 31232\n",
    "args[\"decoder_emd_tok_dim\"] = 31640\n",
    "\n",
    "model_state_dict_new[\"model.encoder_embed_tokens.weight\"] = torch.zeros((args[\"encoder_emd_tok_dim\"], args[\"encoder_embed_dim\"]))\n",
    "\n",
    "model_state_dict_new[\"model.decoder_embed_tokens.weight\"] = torch.zeros((args[\"decoder_emd_tok_dim\"], args[\"decoder_embed_dim\"]))\n",
    "\n",
    "model_state_dict_new[\"model.encoder_embed_tokens.weight\"].shape\n",
    "model_state_dict_new[\"model.decoder_embed_tokens.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FSMTForConditionalGeneration:\n\tUnexpected key(s) in state_dict: \"final_logits_bias\", \"model.encoder_embed_tokens.weight\", \"model.decoder_embed_tokens.weight\". \n\tsize mismatch for model.encoder.embed_positions.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([1026, 1024]).\n\tsize mismatch for model.decoder.embed_positions.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([1026, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-ba265b465e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# show missing or extraneous/mismatching keys (need to remap/change model to match)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state_dict_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/main-38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FSMTForConditionalGeneration:\n\tUnexpected key(s) in state_dict: \"final_logits_bias\", \"model.encoder_embed_tokens.weight\", \"model.decoder_embed_tokens.weight\". \n\tsize mismatch for model.encoder.embed_positions.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([1026, 1024]).\n\tsize mismatch for model.decoder.embed_positions.weight: copying a param with shape torch.Size([1024, 1024]) from checkpoint, the shape in current model is torch.Size([1026, 1024])."
     ]
    }
   ],
   "source": [
    "# show missing or extraneous/mismatching keys (need to remap/change model to match)\n",
    "model_new.load_state_dict(model_state_dict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FSMTForConditionalGeneration(\n",
       "  (model): FSMTModel(\n",
       "    (encoder): FSMTEncoder(\n",
       "      (embed_tokens): Embedding(31232, 1024, padding_idx=1)\n",
       "      (embed_positions): SinusoidalPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EncoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (fc2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): FSMTDecoder(\n",
       "      (embed_tokens): Embedding(31640, 1024, padding_idx=1)\n",
       "      (embed_positions): SinusoidalPositionalEmbedding(1026, 1024, padding_idx=1)\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): DecoderLayer(\n",
       "          (self_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (output_projection): Linear(in_features=1024, out_features=31640, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success!!!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Success!!!\""
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
